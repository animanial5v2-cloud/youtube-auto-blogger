import os
import json
import requests
from typing import Optional, Dict, List
from pytube import YouTube
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import pickle
import base64
from PIL import Image
import io
import re
import html
import xml.etree.ElementTree as ET
import json as jsonlib

# Optional dependency: youtube-transcript-api for robust caption fetching
try:
    from youtube_transcript_api import (
        YouTubeTranscriptApi,
        TranscriptsDisabled,
        NoTranscriptFound,
        VideoUnavailable,
    )
except Exception:
    YouTubeTranscriptApi = None

class YouTubeAutoBlogger:
    def __init__(self, pexels_api_key: Optional[str] = None):
        self.pexels_base_url = "https://api.pexels.com/v1"
        self.pexels_api_key = pexels_api_key
        # OpenAI (GPT) ì„¤ì •: í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© (í•„ìˆ˜)
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        
        # Google Blogger API ì„¤ì •
        self.SCOPES = ['https://www.googleapis.com/auth/blogger']
        self.creds = None
        self.blogger_service = None
        self.log_callback = None
        
    def initialize_blogger_from_token(self) -> bool:
        """token.pickleì´ ìˆìœ¼ë©´ ì´ë¥¼ ì‚¬ìš©í•´ Blogger ì„œë¹„ìŠ¤ë¥¼ ì´ˆê¸°í™”."""
        try:
            if self.blogger_service:
                return True
            if os.path.exists('token.pickle'):
                with open('token.pickle', 'rb') as token:
                    self.creds = pickle.load(token)
                if self.creds:
                    self.blogger_service = build('blogger', 'v3', credentials=self.creds)
                    return True
        except Exception as _:
            return False
        return False
    def setup_google_auth(self, client_id: str = None, client_secret: str = None):
        """Google OAuth 2.0 ì¸ì¦ ì„¤ì •"""
        # í† í°ì´ ì´ë¯¸ ìˆìœ¼ë©´ ë¡œë“œ
        if os.path.exists('token.pickle'):
            with open('token.pickle', 'rb') as token:
                self.creds = pickle.load(token)
        
        # ìœ íš¨í•œ ì¸ì¦ ì •ë³´ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        if not self.creds or not self.creds.valid:
            if self.creds and self.creds.expired and self.creds.refresh_token:
                self.creds.refresh(Request())
            else:
                # credentials.json íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±
                if not os.path.exists('credentials.json'):
                    if client_id and client_secret:
                        # í´ë¼ì´ì–¸íŠ¸ ID/Secretë¡œ credentials.json ìƒì„±
                        self._create_credentials_file(client_id, client_secret)
                    else:
                        print("âš ï¸ credentials.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                        print("Google ì¸ì¦ ì—†ì´ ì½˜í…ì¸  ìƒì„±ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.")
                        return False
                
                flow = InstalledAppFlow.from_client_secrets_file(
                    'credentials.json', self.SCOPES)
                self.creds = flow.run_local_server(port=0)
            
            # í† í° ì €ì¥
            with open('token.pickle', 'wb') as token:
                pickle.dump(self.creds, token)
        
        # Blogger API ì„œë¹„ìŠ¤ ìƒì„±
        try:
            # í”„ë¡ì‹œê°€ TLSë¥¼ ê¹¨ëœ¨ë¦¬ëŠ” í™˜ê²½ì„ íšŒí”¼
            self._disable_system_proxies()
            self.blogger_service = build('blogger', 'v3', credentials=self.creds)
            return True
        except Exception as e:
            print(f"âŒ Blogger API ì„œë¹„ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _create_credentials_file(self, client_id: str, client_secret: str):
        """í´ë¼ì´ì–¸íŠ¸ ID/Secretë¡œ credentials.json íŒŒì¼ ìƒì„±"""
        credentials_data = {
            "installed": {
                "client_id": client_id,
                "client_secret": client_secret,
                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                "token_uri": "https://oauth2.googleapis.com/token",
                "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
                "redirect_uris": ["urn:ietf:wg:oauth:2.0:oob", "http://localhost"]
            }
        }
        
        with open('credentials.json', 'w', encoding='utf-8') as f:
            json.dump(credentials_data, f, indent=2)
        
        print("âœ… credentials.json íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def _disable_system_proxies(self) -> None:
        """ì¼ë¶€ í™˜ê²½ì—ì„œ SSL í”„ë¡ì‹œë¡œ ì¸í•´ TLS í•¸ë“œì…°ì´í¬ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²ƒì„ ë°©ì§€."""
        proxy_vars = [
            'HTTP_PROXY', 'http_proxy',
            'HTTPS_PROXY', 'https_proxy',
            'ALL_PROXY', 'all_proxy',
            'REQUESTS_CA_BUNDLE', 'CURL_CA_BUNDLE'
        ]
        for var in proxy_vars:
            if os.environ.get(var):
                os.environ.pop(var, None)

    def _log(self, message: str) -> None:
        try:
            if self.log_callback:
                self.log_callback(message)
            else:
                print(message)
        except Exception:
            print(message)

    def _llm_generate_text(self, prompt: str) -> Optional[str]:
        """OpenAI(Chat Completions)ìœ¼ë¡œ í…ìŠ¤íŠ¸ ìƒì„±. í‚¤ê°€ ì—†ìœ¼ë©´ ìƒì„± ë¶ˆê°€."""
        if not self.openai_api_key:
            self._log("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AI ìƒì„±ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        try:
            # ì‹œìŠ¤í…œ í”„ë¡ì‹œë¡œ ì¸í•´ TLS ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” í™˜ê²½ ë°©ì§€
            self._disable_system_proxies()
            self._log(f"LLM: OpenAI ({self.openai_model})")
            headers = {"Authorization": f"Bearer {self.openai_api_key}", "Content-Type": "application/json"}
            payload = {
                "model": self.openai_model,
                "messages": [
                    {"role": "system", "content": "You are a helpful assistant that writes fluent Korean when appropriate."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
            }
            session = requests.Session()
            session.trust_env = False  # OS í”„ë¡ì‹œ ë¬´ì‹œ
            resp = session.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload, timeout=120)
            if resp.status_code == 200:
                return resp.json().get("choices", [{}])[0].get("message", {}).get("content")
            else:
                try:
                    txt = resp.text[:500]
                except Exception:
                    txt = str(resp)
                self._log(f"âŒ OpenAI ì‘ë‹µ ì˜¤ë¥˜: {resp.status_code} {txt}")
        except Exception as e:
            self._log(f"âŒ OpenAI í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None
    
    def auto_setup_google_auth(self):
        """ìë™ Google ì¸ì¦ ì„¤ì • (ê¸°ë³¸ê°’ ì‚¬ìš©)"""
        # ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ ID/Secret (ê°œë°œìš©)
        default_client_id = "your-default-client-id.apps.googleusercontent.com"
        default_client_secret = "your-default-client-secret"
        
        print("ğŸ”§ ìë™ Google ì¸ì¦ ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("âš ï¸  ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‹¤ì œ ì‚¬ìš©ì„ ìœ„í•´ì„œëŠ” Google Cloud Consoleì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")
        
        # ì‚¬ìš©ìì—ê²Œ ê¸°ë³¸ê°’ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        try:
            response = input("ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
            if response == 'y':
                return self.setup_google_auth(default_client_id, default_client_secret)
            else:
                print("Google Cloud Consoleì—ì„œ ì„¤ì •ì„ ì™„ë£Œí•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                return False
        except KeyboardInterrupt:
            print("\nì„¤ì •ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return False
    
    def extract_youtube_script(self, youtube_url: str) -> Optional[str]:
        """YouTube URLì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ"""
        try:
            print(f"ğŸ¥ YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì¤‘: {youtube_url}")

            # 1) youtube-transcript-apië¡œ ìë§‰ ìš°ì„  ì‹œë„ (ko -> en)
            def _extract_video_id(url: str) -> Optional[str]:
                patterns = [r"v=([\w-]{11})", r"youtu\.be/([\w-]{11})", r"/shorts/([\w-]{11})"]
                for p in patterns:
                    m = re.search(p, url)
                    if m:
                        return m.group(1)
                return None

            video_id = _extract_video_id(youtube_url)
            # 1) ê³µì‹ timedtext XML ìš°ì„  ì‹œë„ (ë¡œê·¸ì¸/ì œí•œ ì˜ìƒ ì œì™¸)
            if video_id:
                script = self._fetch_timedtext_script(video_id)
                if script:
                    print("âœ… timedtext XMLì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
                    return script
            # 1.5) youtube-transcript-api ë³´ì¡° ì‹œë„ (ìˆìœ¼ë©´)
            if YouTubeTranscriptApi and video_id:
                preferred_langs = ['ko', 'ko-KR', 'en', 'en-US', 'ja', 'zh-Hans', 'zh-Hant', 'zh']
                for attempt in range(2):
                    try:
                        for lang in preferred_langs:
                            try:
                                data = YouTubeTranscriptApi.get_transcript(video_id, languages=[lang])
                                script = "\n".join(seg['text'] for seg in data if seg.get('text'))
                                if script.strip():
                                    print("âœ… ìë§‰ APIì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
                                    return script
                            except Exception:
                                continue
                        break
                    except Exception:
                        break

            # 2) pytubeë¡œ ë©”íƒ€ ì •ë³´(ì œëª©/ì„¤ëª…) í™•ë³´ (ìë§‰ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
            title, description = None, None
            try:
                yt = YouTube(youtube_url)
                title = yt.title
                description = yt.description
            except Exception:
                # oEmbedë¡œ ìµœì†Œ ì œëª© í™•ë³´
                try:
                    oembed = requests.get(
                        "https://www.youtube.com/oembed",
                        params={"url": youtube_url, "format": "json"}, timeout=10,
                    )
                    if oembed.ok:
                        title = oembed.json().get('title')
                except Exception:
                    pass

            # 3) ìë§‰ì´ ì—†ìœ¼ë©´ AIë¡œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
            print("ğŸ“ AIë¡œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
            prompt = f"""
            ë‹¤ìŒ YouTube ë™ì˜ìƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            
            ì œëª©: {title or 'ì œëª© ì—†ìŒ'}
            ì„¤ëª…: {(description or '')[:500]}...
            
            ì‹¤ì œ ìŠ¤í¬ë¦½íŠ¸ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """

            script = self._llm_generate_text(prompt)
            if script:
                print("âœ… AIë¡œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ")
                return script
            else:
                print("âŒ AI ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹¤íŒ¨")
                return None

        except Exception as e:
            print(f"âŒ YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def _fetch_timedtext_script(self, video_id: str) -> Optional[str]:
        """YouTube timedtext XML ì—”ë“œí¬ì¸íŠ¸ë¡œ ìë§‰ì„ í´ë°± ì¶”ì¶œ"""
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´ ëª©ë¡ ì¡°íšŒ
            list_url = "https://video.google.com/timedtext"
            r = requests.get(list_url, params={"type": "list", "v": video_id}, timeout=10)
            if r.status_code != 200 or not r.text.strip():
                return None
            root = ET.fromstring(r.text)
            tracks = root.findall('track')
            if not tracks:
                return None
            # ì„ í˜¸ ì–¸ì–´ ì„ íƒ
            preferred = ['ko', 'ko-KR', 'en', 'en-US']
            lang = None
            for p in preferred:
                if any(t.get('lang_code') == p for t in tracks):
                    lang = p; break
            if not lang:
                lang = tracks[0].get('lang_code')

            # ìë§‰ ë‹¤ìš´ë¡œë“œ (XML)
            r2 = requests.get(list_url, params={"lang": lang, "v": video_id}, timeout=15)
            if r2.status_code != 200 or not r2.text.strip():
                return None
            root2 = ET.fromstring(r2.text)
            lines = []
            for node in root2.findall('text'):
                t = node.text or ''
                t = html.unescape(t)
                t = t.replace('\n', ' ').strip()
                if t:
                    lines.append(t)
            text = "\n".join(lines)
            return text if text.strip() else None
        except Exception:
            return None
    
    def analyze_content(self, script_text: str, target_audience: str = "ì¼ë°˜ì¸", desired_min_len: int = 3000, desired_max_len: int = 4000) -> Dict:
        """AIë¡œ ì½˜í…ì¸  ë¶„ì„ ë° SEO ìµœì í™” (OpenAI ì „ìš©)"""
        # ì•ˆì „ ê°€ë“œ: ë¹„ì •ìƒ ì¸ì êµì •
        try:
            desired_min_len = int(desired_min_len)
            desired_max_len = int(desired_max_len)
            if desired_min_len < 1000:
                desired_min_len = 1000
            if desired_max_len < desired_min_len + 500:
                desired_max_len = desired_min_len + 500
        except Exception:
            desired_min_len, desired_max_len = 3000, 4000

        prompt = f"""
        ë‹¤ìŒ ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ {target_audience} íƒ€ê²Ÿì˜ ê³ í’ˆì§ˆ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        - ê¸¸ì´: ë³¸ë¬¸ì€ {desired_min_len}~{desired_max_len}ì ì‚¬ì´ (ê°€ë…ì„± ìœ ì§€, ë¶ˆí•„ìš”í•œ êµ°ë”ë”ê¸° ê¸ˆì§€)
        - í’ˆì§ˆ: êµ¬ì²´ì  ì‚¬ë¡€/ë°ì´í„°/ì‹¤í–‰ ê°€ëŠ¥í•œ íŒ í¬í•¨, ì¤‘ë³µÂ·ìƒíˆ¬ì  í‘œí˜„ ì§€ì–‘, ê´‘ê³ ì„±Â·ê³¼ì¥ ê¸ˆì§€
        - êµ¬ì¡°: H1 ì œëª©, H2 ì†Œì œëª© 4~6ê°œ, ê° ì†Œì œëª© ì•„ë˜ ìì—°ìŠ¤ëŸ¬ìš´ H3 ìˆ˜ì¤€ì˜ ë‹¨ë½ë“¤ë¡œ êµ¬ì„±
        - SEO: í•œê¸€ í‚¤ì›Œë“œ 10ê°œ, 150ì ë‚´ ë©”íƒ€ ì„¤ëª…, ìì—°ìŠ¤ëŸ¬ìš´ í‚¤ì›Œë“œ ë°°ì¹˜(í‚¤ì›Œë“œ ë‚˜ì—´ ê¸ˆì§€)
        - ê¸ˆì§€ í‘œí˜„ ì˜ˆ: "ì´ ê¸€ì—ì„œëŠ”", "ê²°ë¡ ì ìœ¼ë¡œ", "ìš”ì•½í•˜ë©´" ë“± í…œí”Œë¦¿ ë¬¸êµ¬ ë‚¨ë°œ ê¸ˆì§€
        - ì¶œë ¥ í˜•ì‹: ë°˜ë“œì‹œ 'ìœ íš¨í•œ JSON'ë§Œ ë°˜í™˜. ë§ˆí¬ë‹¤ìš´ ì½”ë“œíœìŠ¤(```), ì¶”ê°€ ì„¤ëª…, ì£¼ì„ ë“± ê¸°íƒ€ í…ìŠ¤íŠ¸ ê¸ˆì§€
        - JSON í‚¤: title, subheadings, content, keywords, meta_description, target_audience

        ìŠ¤í¬ë¦½íŠ¸ ì›ë¬¸:
        {script_text}

        JSONë§Œ ë°˜í™˜:
        {{
            "title": "",
            "subheadings": ["", "", "", ""],
            "content": "",
            "keywords": ["", "", "", "", "", "", "", "", "", ""],
            "meta_description": "",
            "target_audience": "{target_audience}"
        }}
        """
        
        try:
            raw = (self._llm_generate_text(prompt) or '').strip()
            # ì½”ë“œíœìŠ¤ ì œê±° ë° JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            if raw.startswith('```'):
                raw = raw.strip('`')
            def _parse_json(s: str) -> Dict:
                try:
                    return jsonlib.loads(s)
                except Exception:
                    try:
                        start = s.find('{')
                        end = s.rfind('}')
                        if start != -1 and end != -1:
                            return jsonlib.loads(s[start:end+1])
                    except Exception:
                        pass
                return {}

            data = _parse_json(raw) or {}
            if not data:
                # ìµœì†Œ êµ¬ì¡° ë°˜í™˜
                data = {
                    "title": f"{target_audience}ì„ ìœ„í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸",
                    "subheadings": ["ì£¼ìš” ë‚´ìš©", "ìƒì„¸ ì„¤ëª…", "ê²°ë¡ "],
                    "content": raw,
                    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", "í‚¤ì›Œë“œ4", "í‚¤ì›Œë“œ5",
                                   "í‚¤ì›Œë“œ6", "í‚¤ì›Œë“œ7", "í‚¤ì›Œë“œ8", "í‚¤ì›Œë“œ9", "í‚¤ì›Œë“œ10"],
                    "meta_description": "ìœ íŠœë¸Œ ì½˜í…ì¸ ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                    "target_audience": target_audience
                }

            # ë³¸ë¬¸ ê¸¸ì´ ë³´ì •(ëª©í‘œ {desired_min_len}~{desired_max_len}ì)
            try:
                body = (data.get('content') or '').strip()
                body_len = len(body)
                if body_len < desired_min_len:
                    expand_prompt = f"""
                    ì•„ë˜ ë³¸ë¬¸ì„ {desired_min_len}~{desired_max_len}ì ë²”ìœ„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í™•ì¥í•˜ì„¸ìš”.
                    - ì†Œì œëª©(H2)ë³„ë¡œ êµ¬ì²´ ì‚¬ë¡€/ë°ì´í„°/ì‹¤í–‰ íŒ ë³´ê°•
                    - ì¤‘ë³µ ì œê±°, ë°€ë„ ë†’ê²Œ ì„œìˆ , ìƒíˆ¬ì  ë¬¸êµ¬ ê¸ˆì§€
                    - ë°˜í™˜ì€ 'ë³¸ë¬¸ í…ìŠ¤íŠ¸'ë§Œ. ë‹¤ë¥¸ í˜•ì‹Â·ì£¼ì„Â·ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€

                    ë³¸ë¬¸:
                    {body}
                    """
                    r_len_text = self._llm_generate_text(expand_prompt)
                    if r_len_text:
                        data['content'] = r_len_text.strip()
                elif body_len > desired_max_len:
                    shrink_prompt = f"""
                    ì•„ë˜ ë³¸ë¬¸ì„ í•µì‹¬ì€ ìœ ì§€í•˜ë˜ {desired_min_len}~{desired_max_len}ìë¡œ ì‘ì¶•í•˜ì„¸ìš”.
                    - ì •ë³´ ì†ì‹¤ ìµœì†Œí™”, ë¶ˆí•„ìš”í•œ ìˆ˜ì‚¬/ì¤‘ë³µ ì œê±°
                    - ë¬¸ì¥ ê°„ ê²°ì† ê°•í™”, ë…¼ë¦¬ íë¦„ ìœ ì§€
                    - ë°˜í™˜ì€ 'ë³¸ë¬¸ í…ìŠ¤íŠ¸'ë§Œ. ë‹¤ë¥¸ í˜•ì‹Â·ì£¼ì„Â·ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€

                    ë³¸ë¬¸:
                    {body}
                    """
                    r_len_text = self._llm_generate_text(shrink_prompt)
                    if r_len_text:
                        data['content'] = r_len_text.strip()
            except Exception:
                pass

            # í•œê¸€ ê°•ì œ: ë³¸ë¬¸ì´ ì˜ì–´ ìœ„ì£¼ë©´ í•œêµ­ì–´ë¡œ ë³€í™˜
            try:
                text = data.get('content') or ''
                # ê°„ë‹¨í•œ í•œê¸€ ë¬¸ì ë¹„ìœ¨ ì²´í¬
                hangul = sum(1 for ch in text if '\uac00' <= ch <= '\ud7a3')
                ratio = hangul / max(len(text), 1)
                if ratio < 0.2 and text.strip():
                    to_kr_prompt = f"""
                    ë‹¤ìŒ ì˜ì–´(ë˜ëŠ” ë¹„í•œêµ­ì–´) ë¸”ë¡œê·¸ ë³¸ë¬¸ì„ í•œêµ­ì–´ë¡œ ë§¤ë„ëŸ½ê²Œ ë²ˆì—­í•˜ë˜, ì˜ë¯¸ë¥¼ ì¶©ì‹¤íˆ ë°˜ì˜í•˜ì„¸ìš”.
                    - ì¡´ëŒ“ë§, ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥
                    - ë§ˆí¬ë‹¤ìš´/ì½”ë“œíœìŠ¤ ê¸ˆì§€, ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜

                    ë³¸ë¬¸:
                    {text}
                    """
                    r3_text = self._llm_generate_text(to_kr_prompt)
                    if r3_text:
                        data['content'] = r3_text
            except Exception:
                pass

            return data
                
        except Exception as e:
            print(f"âŒ ì½˜í…ì¸  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def translate_keywords_to_english(self, keywords: List[str]) -> List[str]:
        """í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­"""
        prompt = f"""
        ë‹¤ìŒ í•œê¸€ í‚¤ì›Œë“œë“¤ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. 
        ì´ë¯¸ì§€ ê²€ìƒ‰ì— ì í•©í•œ ì˜ì–´ ë‹¨ì–´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
        
        í‚¤ì›Œë“œ: {', '.join(keywords[:5])}
        
        ì˜ì–´ í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        try:
            text = self._llm_generate_text(prompt)
            if text:
                english_keywords = text.strip().split(',')
                return [kw.strip() for kw in english_keywords]
            return keywords[:5]
        except Exception as e:
            print(f"âŒ í‚¤ì›Œë“œ ë²ˆì—­ ì‹¤íŒ¨: {e}")
            return keywords[:5]
    
    def search_pexels_image(self, keyword: str) -> Optional[str]:
        """Pexelsì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰"""
        try:
            headers = {}
            if self.pexels_api_key:
                headers['Authorization'] = self.pexels_api_key
            
            url = f"{self.pexels_base_url}/search"
            params = {
                'query': keyword,
                'per_page': 1,
                'orientation': 'landscape'
            }
            
            response = requests.get(url, headers=headers, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                if data['photos']:
                    photo = data['photos'][0]
                    return photo['src']['large']
            else:
                print(f"Pexels API ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return None
    
    def create_blog_post_content(self, analysis: Dict, image_url: Optional[str] = None) -> str:
        """ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ HTML ìƒì„±"""
        title = analysis.get('title', 'ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸')
        subheadings = analysis.get('subheadings', [])
        content = analysis.get('content', '')
        keywords = analysis.get('keywords', [])
        
        html_content = f"""
        <h1>{title}</h1>
        """

        # ì´ë¯¸ì§€ ì¶”ê°€ (ì›ë³¸ ì œëª©ì„ altë¡œ ì‚¬ìš©í•´ ì´ë¯¸ì§€ ê²€ìƒ‰ ìµœì í™”)
        if image_url:
            html_content += (
                f'<img src="{image_url}" alt="{title}" title="{title}" '
                f'style="max-width: 100%; height: auto; margin: 20px 0;" />'
            )

        # ì „ì²´ ë³¸ë¬¸ì„ ì†Œì œëª© ê°œìˆ˜ì— ë§ì¶° ê· ë“± ë¶„í• í•˜ì—¬ ëª¨ë“  ë¬¸ë‹¨ì„ í¬í•¨
        # - LLM ì¶œë ¥ì´ \n\n ë‹¨ë½ êµ¬ë¶„ì„ ì‚¬ìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆì–´ ë³´ì¡° ë¶„í• ì„ ì‚¬ìš©
        raw_parts = [p.strip() for p in content.split('\n\n') if p.strip()]
        if len(raw_parts) <= 1:
            raw_parts = [p.strip() for p in content.split('\n') if p.strip()]
        if not raw_parts:
            raw_parts = [content.strip()]

        if subheadings:
            num_sections = max(1, len(subheadings))
            # êµ¬ê°„ ê²½ê³„: ë¶„í•  ì†ì‹¤ ì—†ì´ ëª¨ë“  ë‹¨ë½ í¬í•¨
            total = len(raw_parts)
            for idx, sub in enumerate(subheadings):
                start = (idx * total) // num_sections
                end = ((idx + 1) * total) // num_sections
                chunk = raw_parts[start:end] if start < end else []
                html_content += f"""
                <h2>{sub}</h2>
                {''.join(f'<p>{para}</p>' for para in chunk) if chunk else ''}
                """
            # ë‚¨ëŠ” ë‹¨ë½ì´ ìˆë‹¤ë©´ ë§ˆì§€ë§‰ ì„¹ì…˜ ë’¤ì— ì•ˆì „í•˜ê²Œ ì¶”ê°€
            if len(raw_parts) > (((len(subheadings)) * total) // num_sections):
                leftover = raw_parts[((len(subheadings)) * total) // num_sections:]
                html_content += """
                <div>
                {paras}
                </div>
                """.replace('{paras}', ''.join(f'<p>{p}</p>' for p in leftover))
        else:
            # ì†Œì œëª©ì´ ì—†ìœ¼ë©´ ë³¸ë¬¸ ì „ì²´ë¥¼ ë‹¨ë½ìœ¼ë¡œ ì¶œë ¥
            html_content += ''.join(f'<p>{p}</p>' for p in raw_parts)

        # í‚¤ì›Œë“œ ì„¹ì…˜ ì¶”ê°€
        html_content += f"""
        <h3>ê´€ë ¨ í‚¤ì›Œë“œ</h3>
        <p>{', '.join(keywords)}</p>
        """

        return html_content
    
    def post_to_blogger(self, blog_id: str, title: str, content: str, labels: List[str] = None,
                        publish_at_iso: Optional[str] = None) -> Optional[str]:
        """êµ¬ê¸€ ë¸”ë¡œê±°ì— í¬ìŠ¤íŠ¸ ì‘ì„± í›„ ê³µê°œ URL ë°˜í™˜ (ì‹¤íŒ¨ ì‹œ None)
        ì˜ˆì•½ ë°œí–‰: publish_at_iso(ISO8601/RFC3339)ê°€ ë¯¸ë˜ ì‹œê°„ì´ë©´ ì´ˆì•ˆ ìƒì„± í›„ í•´ë‹¹ ì‹œê°ìœ¼ë¡œ ë°œí–‰
        """
        try:
            if not self.blogger_service:
                print("âŒ Blogger ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
            
            post_body = {
                'kind': 'blogger#post',
                'blog': {
                    'id': blog_id
                },
                'title': title,
                'content': content,
                'labels': labels or []
            }
            
            if publish_at_iso:
                # ì´ˆì•ˆìœ¼ë¡œ ìƒì„± í›„ ì˜ˆì•½ ë°œí–‰
                draft = self.blogger_service.posts().insert(
                    blogId=blog_id,
                    body=post_body,
                    isDraft=True
                ).execute()
                post_id = draft.get('id')
                if not post_id:
                    print("âŒ ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨")
                    return None
                pub = self.blogger_service.posts().publish(
                    blogId=blog_id,
                    postId=post_id,
                    publishDate=publish_at_iso
                ).execute()
                url = pub.get('url')
                print(f"âœ… ì˜ˆì•½ ë°œí–‰ ì„¤ì • ì™„ë£Œ: {url} @ {publish_at_iso}")
                return url
            else:
                # ì¦‰ì‹œ ë°œí–‰
                post = self.blogger_service.posts().insert(
                    blogId=blog_id,
                    body=post_body,
                    isDraft=False
                ).execute()
                url = post.get('url')
                print(f"âœ… ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ: {url}")
                return url
            
        except HttpError as error:
            print(f"âŒ Blogger API ì˜¤ë¥˜: {error}")
            return None
        except Exception as e:
            print(f"âŒ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì‘ì„± ì‹¤íŒ¨: {e}")
            return None
    
    def get_user_blogs(self) -> List[Dict]:
        """ì‚¬ìš©ìì˜ ë¸”ë¡œê·¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            if not self.blogger_service:
                return []
            
            blogs = self.blogger_service.blogs().listByUser(userId='self').execute()
            return blogs.get('items', [])
            
        except Exception as e:
            print(f"âŒ ë¸”ë¡œê·¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []
    
    def generate_full_auto_package(self, youtube_url: str, target_audience: str = "ì¼ë°˜ì¸", blog_id: str = None,
                                   min_len: int = 3000, max_len: int = 4000,
                                   publish_at_iso: Optional[str] = None) -> Dict:
        """ì™„ì „ ìë™í™”ëœ íŒ¨í‚¤ì§€ ìƒì„±"""
        print("ğŸš€ YouTube ìë™ ë¸”ë¡œê±° ì‹œì‘...")
        
        # 1. YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
        script_text = self.extract_youtube_script(youtube_url)
        if not script_text:
            return {"error": "YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"}
        
        # 2. AIë¡œ ì½˜í…ì¸  ë¶„ì„
        print("ğŸ“Š ì½˜í…ì¸  ë¶„ì„ ì¤‘...")
        analysis = self.analyze_content(script_text, target_audience, desired_min_len=min_len, desired_max_len=max_len)
        if not analysis:
            return {"error": "ì½˜í…ì¸  ë¶„ì„ ì‹¤íŒ¨"}
        
        # 3. í‚¤ì›Œë“œ ë²ˆì—­
        print("ğŸŒ í‚¤ì›Œë“œ ë²ˆì—­ ì¤‘...")
        english_keywords = self.translate_keywords_to_english(analysis.get('keywords', []))
        
        # 4. ì´ë¯¸ì§€ ê²€ìƒ‰
        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
        image_url = None
        for keyword in english_keywords:
            image_url = self.search_pexels_image(keyword)
            if image_url:
                break
        
        # 5. ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì½˜í…ì¸  ìƒì„±
        print("âœï¸ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
        blog_content = self.create_blog_post_content(analysis, image_url)
        
        # 6. êµ¬ê¸€ ë¸”ë¡œê±°ì— í¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
        post_url: Optional[str] = None
        if blog_id and self.blogger_service:
            print("ğŸ“ êµ¬ê¸€ ë¸”ë¡œê±°ì— í¬ìŠ¤íŠ¸ ì¤‘...")
            post_url = self.post_to_blogger(
                blog_id, 
                analysis.get('title', 'ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'),
                blog_content,
                analysis.get('keywords', []),
                publish_at_iso=publish_at_iso
            )
            # post_urlì€ ì‹¤ì œ ê³µê°œ URLì´ê±°ë‚˜ None
        
        return {
            "success": True,
            "youtube_url": youtube_url,
            "script": script_text,
            "analysis": analysis,
            "english_keywords": english_keywords,
            "image_url": image_url,
            "blog_content": blog_content,
            "post_url": post_url,
            "target_audience": target_audience
        }
    
    def save_to_files(self, package: Dict, output_dir: str = "auto_blogger_output"):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        # HTML íŒŒì¼
        html_content = f"""
        <!DOCTYPE html>
        <html lang="ko">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>{package['analysis'].get('title', 'ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸')}</title>
            <meta name="description" content="{package['analysis'].get('meta_description', '')}">
            <style>
                body {{ font-family: Arial, sans-serif; line-height: 1.6; margin: 40px; }}
                h1 {{ color: #333; border-bottom: 2px solid #eee; padding-bottom: 10px; }}
                h2 {{ color: #555; margin-top: 30px; }}
                h3 {{ color: #666; }}
                img {{ max-width: 100%; height: auto; margin: 20px 0; border-radius: 8px; }}
                .keywords {{ background: #f9f9f9; padding: 15px; border-radius: 5px; margin-top: 20px; }}
            </style>
        </head>
        <body>
            {package['blog_content']}
            <div class="keywords">
                <h3>ğŸ“Š ìƒì„± ì •ë³´</h3>
                <p><strong>YouTube URL:</strong> {package['youtube_url']}</p>
                <p><strong>íƒ€ê²Ÿ:</strong> {package['target_audience']}</p>
                <p><strong>ê²€ìƒ‰ í‚¤ì›Œë“œ:</strong> {', '.join(package['english_keywords'])}</p>
                {f'<p><strong>ì´ë¯¸ì§€ URL:</strong> {package["image_url"]}</p>' if package['image_url'] else ''}
                {f'<p><strong>ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸:</strong> <a href="{package["post_url"]}" target="_blank">ë³´ê¸°</a></p>' if package['post_url'] else ''}
            </div>
        </body>
        </html>
        """
        
        with open(f"{output_dir}/blog_post.html", "w", encoding="utf-8") as f:
            f.write(html_content)
        
        # JSON íŒŒì¼
        with open(f"{output_dir}/package_data.json", "w", encoding="utf-8") as f:
            json.dump(package, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_dir}/")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¥ YouTube ìë™ ë¸”ë¡œê±°")
    print("=" * 50)
    
    # Google ì¸ì¦ ì„¤ì •
    auto_blogger = YouTubeAutoBlogger()
    if not auto_blogger.setup_google_auth():
        print("âŒ Google ì¸ì¦ ì„¤ì • ì‹¤íŒ¨")
        return
    
    # ì‚¬ìš©ì ì…ë ¥
    youtube_url = input("YouTube URLì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    target_audience = input("íƒ€ê²Ÿì„ ì„ íƒí•˜ì„¸ìš” (ì¼ë°˜ì¸/ì „ë¬¸ê°€/ì—¬ì/ë‚¨ì): ").strip() or "ì¼ë°˜ì¸"
    blog_id = input("êµ¬ê¸€ ë¸”ë¡œê·¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­): ").strip() or None
    
    # ìë™í™” íŒ¨í‚¤ì§€ ìƒì„±
    package = auto_blogger.generate_full_auto_package(youtube_url, target_audience, blog_id)
    
    if package.get("success"):
        print("âœ… ìë™í™” ì™„ë£Œ!")
        print(f"ğŸ“ ì œëª©: {package['analysis'].get('title', 'N/A')}")
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€: {'ìˆìŒ' if package['image_url'] else 'ì—†ìŒ'}")
        print(f"ğŸ“Š í‚¤ì›Œë“œ: {len(package['english_keywords'])}ê°œ")
        if package['post_url']:
            print(f"ğŸŒ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸: {package['post_url']}")
        
        # íŒŒì¼ ì €ì¥
        auto_blogger.save_to_files(package)
    else:
        print(f"âŒ ì˜¤ë¥˜: {package.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

if __name__ == "__main__":
    main()

