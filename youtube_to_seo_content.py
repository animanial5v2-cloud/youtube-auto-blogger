import requests
import json
import re
from datetime import datetime
import os
from typing import Dict, List, Optional
import openai
from PIL import Image, ImageDraw, ImageFont
import io
import base64

class YouTubeToSEOContent:
    def __init__(self, openai_api_key: str):
        """ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ SEO ìµœì í™”ëœ ì½˜í…ì¸ ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
        self.openai_api_key = openai_api_key
        openai.api_key = openai_api_key
        
    def extract_youtube_id(self, url: str) -> str:
        """ìœ íŠœë¸Œ URLì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ"""
        patterns = [
            r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)',
            r'youtube\.com\/v\/([^&\n?#]+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        raise ValueError("ìœ íš¨í•œ ìœ íŠœë¸Œ URLì´ ì•„ë‹™ë‹ˆë‹¤.")
    
    def get_video_info(self, video_id: str) -> Dict:
        """ìœ íŠœë¸Œ ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (YouTube Data API ì‚¬ìš©)"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” YouTube Data API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤
        return {
            "title": "ìƒ˜í”Œ ë¹„ë””ì˜¤ ì œëª©",
            "description": "ìƒ˜í”Œ ë¹„ë””ì˜¤ ì„¤ëª…",
            "duration": "10:30",
            "view_count": "10000",
            "like_count": "500"
        }
    
    def analyze_script(self, script_text: str) -> Dict:
        """ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„í•˜ì—¬ í‚¤ì›Œë“œ, ì£¼ì œ, êµ¬ì¡° ì¶”ì¶œ"""
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:"
                    },
                    {
                        "role": "user",
                        "content": f"""
                        ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
                        
                        {script_text}
                        
                        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
                        {{
                            "main_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
                            "long_tail_keywords": ["ë¡±í…Œì¼ í‚¤ì›Œë“œ1", "ë¡±í…Œì¼ í‚¤ì›Œë“œ2"],
                            "main_topic": "ì£¼ìš” ì£¼ì œ",
                            "sub_topics": ["ì„œë¸Œ ì£¼ì œ1", "ì„œë¸Œ ì£¼ì œ2"],
                            "target_audience": "íƒ€ê²Ÿ ë…ì",
                            "content_structure": ["ì„¹ì…˜1", "ì„¹ì…˜2", "ì„¹ì…˜3"],
                            "seo_title": "SEO ìµœì í™”ëœ ì œëª©",
                            "meta_description": "ë©”íƒ€ ì„¤ëª…"
                        }}
                        """
                    }
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            print(f"ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._get_default_analysis()
    
    def generate_seo_content(self, analysis: Dict, script_text: str) -> Dict:
        """SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±"""
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": f"""
                        ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
                        
                        ë¶„ì„ ê²°ê³¼: {json.dumps(analysis, ensure_ascii=False)}
                        ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸: {script_text[:1000]}...
                        
                        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
                        1. SEO ìµœì í™”ëœ ì œëª©
                        2. ë©”íƒ€ ì„¤ëª…
                        3. ë„ì…ë¶€ (ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ”)
                        4. ì£¼ìš” ë‚´ìš© (H2, H3 íƒœê·¸ í¬í•¨)
                        5. ê²°ë¡ 
                        6. ê´€ë ¨ í‚¤ì›Œë“œ
                        7. ë‚´ë¶€/ì™¸ë¶€ ë§í¬ ì œì•ˆ
                        
                        HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                        """
                    }
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            return {
                "html_content": response.choices[0].message.content,
                "analysis": analysis
            }
            
        except Exception as e:
            print(f"ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._get_default_content(analysis)
    
    def generate_images(self, analysis: Dict, content: str) -> List[str]:
        """ì½˜í…ì¸ ì— ë§ëŠ” ì´ë¯¸ì§€ ìƒì„± (DALL-E ì‚¬ìš©)"""
        images = []
        
        try:
            # ë©”ì¸ ì´ë¯¸ì§€ ìƒì„±
            main_prompt = f"SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ìš© ì´ë¯¸ì§€: {analysis.get('main_topic', '')}"
            
            response = openai.Image.create(
                prompt=main_prompt,
                n=1,
                size="1024x1024"
            )
            
            images.append(response['data'][0]['url'])
            
            # ì¶”ê°€ ì´ë¯¸ì§€ë“¤ ìƒì„±
            for i, sub_topic in enumerate(analysis.get('sub_topics', [])[:3]):
                sub_prompt = f"ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì„¹ì…˜ ì´ë¯¸ì§€: {sub_topic}"
                
                response = openai.Image.create(
                    prompt=sub_prompt,
                    n=1,
                    size="512x512"
                )
                
                images.append(response['data'][0]['url'])
                
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±
            images = self._generate_default_images(analysis)
        
        return images
    
    def create_social_media_content(self, analysis: Dict, content: str) -> Dict:
        """ì†Œì…œë¯¸ë””ì–´ìš© ì½˜í…ì¸  ìƒì„±"""
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ì†Œì…œë¯¸ë””ì–´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": f"""
                        ë‹¤ìŒ ì½˜í…ì¸ ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì†Œì…œë¯¸ë””ì–´ìš© í¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
                        
                        ì£¼ì œ: {analysis.get('main_topic', '')}
                        í‚¤ì›Œë“œ: {analysis.get('main_keywords', [])}
                        
                        ë‹¤ìŒ í”Œë«í¼ë³„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
                        1. Instagram (í•´ì‹œíƒœê·¸ í¬í•¨)
                        2. Twitter (280ì ì´ë‚´)
                        3. LinkedIn (ì „ë¬¸ì  í†¤)
                        4. Facebook
                        
                        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
                        """
                    }
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            print(f"ì†Œì…œë¯¸ë””ì–´ ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._get_default_social_content(analysis)
    
    def generate_full_package(self, youtube_url: str, script_text: str) -> Dict:
        """ì „ì²´ SEO íŒ¨í‚¤ì§€ ìƒì„±"""
        print("ğŸ” ìœ íŠœë¸Œ URL ë¶„ì„ ì¤‘...")
        video_id = self.extract_youtube_id(youtube_url)
        video_info = self.get_video_info(video_id)
        
        print("ğŸ“ ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„ ì¤‘...")
        analysis = self.analyze_script(script_text)
        
        print("âœï¸ SEO ì½˜í…ì¸  ìƒì„± ì¤‘...")
        content = self.generate_seo_content(analysis, script_text)
        
        print("ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        images = self.generate_images(analysis, content['html_content'])
        
        print("ğŸ“± ì†Œì…œë¯¸ë””ì–´ ì½˜í…ì¸  ìƒì„± ì¤‘...")
        social_content = self.create_social_media_content(analysis, content['html_content'])
        
        return {
            "video_info": video_info,
            "analysis": analysis,
            "seo_content": content,
            "images": images,
            "social_media": social_content,
            "generated_at": datetime.now().isoformat()
        }
    
    def save_to_files(self, package: Dict, output_dir: str = "seo_output"):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        # HTML íŒŒì¼ ì €ì¥
        with open(f"{output_dir}/blog_post.html", "w", encoding="utf-8") as f:
            f.write(package['seo_content']['html_content'])
        
        # ë¶„ì„ ê²°ê³¼ JSON ì €ì¥
        with open(f"{output_dir}/analysis.json", "w", encoding="utf-8") as f:
            json.dump(package['analysis'], f, ensure_ascii=False, indent=2)
        
        # ì†Œì…œë¯¸ë””ì–´ ì½˜í…ì¸  ì €ì¥
        with open(f"{output_dir}/social_media.json", "w", encoding="utf-8") as f:
            json.dump(package['social_media'], f, ensure_ascii=False, indent=2)
        
        # ì´ë¯¸ì§€ URL ì €ì¥
        with open(f"{output_dir}/images.txt", "w", encoding="utf-8") as f:
            for i, img_url in enumerate(package['images']):
                f.write(f"Image {i+1}: {img_url}\n")
        
        print(f"âœ… ëª¨ë“  íŒŒì¼ì´ {output_dir} í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    def _get_default_analysis(self) -> Dict:
        """ê¸°ë³¸ ë¶„ì„ ê²°ê³¼"""
        return {
            "main_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
            "long_tail_keywords": ["ë¡±í…Œì¼ í‚¤ì›Œë“œ"],
            "main_topic": "ì£¼ìš” ì£¼ì œ",
            "sub_topics": ["ì„œë¸Œ ì£¼ì œ1", "ì„œë¸Œ ì£¼ì œ2"],
            "target_audience": "ì¼ë°˜ ë…ì",
            "content_structure": ["ë„ì…", "ë³¸ë¬¸", "ê²°ë¡ "],
            "seo_title": "SEO ìµœì í™”ëœ ì œëª©",
            "meta_description": "ë©”íƒ€ ì„¤ëª…"
        }
    
    def _get_default_content(self, analysis: Dict) -> Dict:
        """ê¸°ë³¸ ì½˜í…ì¸ """
        return {
            "html_content": f"""
            <h1>{analysis.get('seo_title', 'ì œëª©')}</h1>
            <p>{analysis.get('meta_description', 'ì„¤ëª…')}</p>
            <h2>ë„ì…</h2>
            <p>ë„ì… ë‚´ìš©...</p>
            <h2>ë³¸ë¬¸</h2>
            <p>ë³¸ë¬¸ ë‚´ìš©...</p>
            <h2>ê²°ë¡ </h2>
            <p>ê²°ë¡  ë‚´ìš©...</p>
            """,
            "analysis": analysis
        }
    
    def _get_default_social_content(self, analysis: Dict) -> Dict:
        """ê¸°ë³¸ ì†Œì…œë¯¸ë””ì–´ ì½˜í…ì¸ """
        return {
            "instagram": f"ğŸ“± {analysis.get('main_topic', 'ì£¼ì œ')} #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2",
            "twitter": f"ğŸ” {analysis.get('main_topic', 'ì£¼ì œ')}ì— ëŒ€í•´ ì•Œì•„ë³´ì„¸ìš”!",
            "linkedin": f"ğŸ’¼ {analysis.get('main_topic', 'ì£¼ì œ')}ì— ëŒ€í•œ ì „ë¬¸ì ì¸ ë¶„ì„",
            "facebook": f"ğŸ“– {analysis.get('main_topic', 'ì£¼ì œ')}ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©"
        }
    
    def _generate_default_images(self, analysis: Dict) -> List[str]:
        """ê¸°ë³¸ ì´ë¯¸ì§€ URL (ì‹¤ì œë¡œëŠ” ë” ë‚˜ì€ ë°©ë²• í•„ìš”)"""
        return [
            "https://via.placeholder.com/1024x1024/007bff/ffffff?text=Main+Image",
            "https://via.placeholder.com/512x512/28a745/ffffff?text=Section+1",
            "https://via.placeholder.com/512x512/dc3545/ffffff?text=Section+2"
        ]

# ì‚¬ìš© ì˜ˆì‹œ
def main():
    # OpenAI API í‚¤ ì„¤ì • (ì‹¤ì œ ì‚¬ìš©ì‹œ í•„ìš”)
    OPENAI_API_KEY = "your-openai-api-key-here"
    
    # í”„ë¡œê·¸ë¨ ì´ˆê¸°í™”
    converter = YouTubeToSEOContent(OPENAI_API_KEY)
    
    # ì‚¬ìš©ì ì…ë ¥
    print("ğŸ¥ ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ SEO ì½˜í…ì¸ ë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡œê·¸ë¨")
    print("=" * 50)
    
    youtube_url = input("ìœ íŠœë¸Œ URLì„ ì…ë ¥í•˜ì„¸ìš”: ")
    print("\nìŠ¤í¬ë¦½íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì…ë ¥ ì™„ë£Œ í›„ Ctrl+D ë˜ëŠ” Ctrl+Z):")
    
    script_lines = []
    try:
        while True:
            line = input()
            script_lines.append(line)
    except (EOFError, KeyboardInterrupt):
        pass
    
    script_text = "\n".join(script_lines)
    
    if not script_text.strip():
        print("âŒ ìŠ¤í¬ë¦½íŠ¸ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # SEO íŒ¨í‚¤ì§€ ìƒì„±
    print("\nğŸš€ SEO íŒ¨í‚¤ì§€ ìƒì„± ì¤‘...")
    package = converter.generate_full_package(youtube_url, script_text)
    
    # íŒŒì¼ë¡œ ì €ì¥
    converter.save_to_files(package)
    
    print("\nğŸ‰ ì™„ë£Œ! ìƒì„±ëœ íŒŒì¼ë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”:")
    print("- blog_post.html: SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸")
    print("- analysis.json: í‚¤ì›Œë“œ ë° ë¶„ì„ ê²°ê³¼")
    print("- social_media.json: ì†Œì…œë¯¸ë””ì–´ìš© ì½˜í…ì¸ ")
    print("- images.txt: ìƒì„±ëœ ì´ë¯¸ì§€ URLë“¤")

if __name__ == "__main__":
    main()
